[Timelines ML](../../)

# NAICS Training Data for ML

North American Industry Classification System (NAICS)
We're creating a new Random Forest process informed [by the prior zip code zcta process](../../prep/all)

We're using the state of Maine (ME) for our sample counties.  
We're using NAICS levels 2 and 4 in our training files.

Our ML Group focus areas: 
- [PyTorch ML and Data Visualization](/machine-learning/pytorch/cluster/) - Network Graphs, Sankey and Chord - Honglin, Rupesh
- [Sankey Industry Chart](/io/charts/sankey/)
- [Chord Chart Data Prep](/io/charts/chord/)
- [Bee the Predictor](/data-pipeline/research/bees/) - with [TensorFlow Javascript](https://www.tensorflow.org/js/demos) - Irene
- [Tree Canopy Data](/data-pipeline/research/canopy/)

Sijia, Kargil, Alison, Irene, Honglin, Ronan, Lily, Luwei, Wenxi, Magie and more.

1.) Training files are generated by our team's [CoLab on Google](https://colab.research.google.com/drive/1wmJ3V9eqD8KbmBiP-hLeSstwOUt5iS2V?usp=sharing) a ML-bkup.ipynb backup copy resides here in the "python" subfolder. <!-- - Lily, Sijia, R -->
2.) Training files are output to our [community-timelines repo](https://github.com/ModelEarth/community-timelines/tree/main/training/naic4/US/counties).
3.) TO DO: Apply Random Forest forecasting. - Sijia will copy our prior .py file into a CoLab. Code it to work for both FIPS and ZCTA.
4.) TO DO: Aiming for these results:
- Top ten Maine counties at risk of increased poverty - Use Google Data Commons API for county poverty data and international data. Pull with an [Observable Data Loader](../../../timelines/observable/) - Kargil, Parth and others
- Top ten Maine counties likely to have declining [bee populations](../../../research/bees/) - Irene
- Top ten Maine counties likely to have [declining tree canopy](/data-pipeline/research/canopy/) - Find a data source (county or zip)

5.) TO DO: Find equivalent data for China, or geneate with ML and Google Data Commons.
6.) TO DO: [Create an easy way for non-coders to setup Observable visualizations](/data-pipeline/timelines/observable) - Kargil, Parth and others
7.) TO DO: [Apply y=1 on-the-fly](/data-pipeline/research/bees/) with Javascript and [Observable](../../observable/).
8.) TO DO: Use [Tensorflow.org](https://www.tensorflow.org/js/demos) for [Neural Network predictions](https://www.tensorflow.org/s/results/?q=neural%20networks).

### Javascript Display in Tabulator

In javascript, we'll populate "Density" for each county and append it as a column in Tabulator. [Tabulator work in progress](/data-pipeline/timelines/tabulator/).

Density = Population / Km2

Density can also be thought of as PopPerKm2 (divided by 1000)
100,000 people living in an 80 Km2 county = 1250 people per Km2 = Density of 1.25
When displaying, we will multiply Density and Population by 1000.


### Start a virtual environment

Run python in your modelearth webroot since you'll be sending files to data repos.

      python3 -m venv env && source env/bin/activate
      && cd data-pipeline/timelines/training/naics


## Current Projects

### 1. Prepare Python that loads naics4 data into Pandas for 2017 to 2021 for Maine

DONE - Project Contact: Yanqing (Lily)

Source files. Load these directly from the URL into Pandas.

https://model.earth/community-data/industries/naics/US/counties/ME/US-ME-census-naics4-counties-2021.csv

View source files on GitHub: [industries/naics/US/counties/ME](https://github.com/ModelEarth/community-data/tree/master/industries/naics/US/counties/ME)

---


### 2. Output annual training files

In Progress - CoLab link at the top of this page.

Output: One row per location (county) with columns for all naics4 industries with 3 attributes.

Save to: output/2021/US-ME-training-naics4-counties-2021.csv

Later these will reside in /community-forecasting

Attributes:
Industry's Establishments per 1000 people
Industry's Employees per 1000 people
Industry's Average pay per Employee

We'll need a Python library that pulls the county population by year.
Let's also include the value of the center latitude and longitude.
We could include the county name, then see if the model predicts differently without it.

A file called columns.md could be output with a list of the column values:

Fips
Name
Population
Latitude
Longitude
Naics X Establishments per 1000
Naics X Employees per 1000
Naics X Average pay
[repeat]

<!--
Fips, N1111-Firms, N1111-People, N1111-Pay, N2222-Firms, N2222-People, N2222-Pay, ...

The following attribute names are equivalent:

Firms = Establishments
People = Employees
Pay = Payroll
-->

As a reference, the prior structure for zcta (zip code) training data was:
Zcta, JobsTotal, JobsAgriculture, JobsEntertainment, Population, Poverty, PovertyUnder18, Education, WorkExperience, y

Ronan is working on a similar pivot in [prep/industries](../../prep/industries/) for timelines, except the timeline rows are years.

---

### Append 0 or 1 to the last column.

County demographic attributes can be fetched from the Google Data Commons API for population, education levels, income/poverty levels.

Prior y column:
y=1 when the current year’s poverty had no decline from the prior year AND the next year’s poverty increased by 2% or more.
<!--
Applied in
prep/all/zcta_2016.SQL.txt

-- Change from prior year is steady (0%) or increasing, change to next year is increasing by 2% or more.

CASE
      WHEN (prior1.poverty - p.poverty) >= 0 AND (p.poverty - next.poverty) >= 2 THEN 1
      ELSE 0
END

AS y -- the povertyBinary for >= 2% in coming year, and no decline for current year.
-->

---
<br>

### Display results of Random Forest

Sample from prior zcta process: